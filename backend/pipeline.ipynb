{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "    roc_auc_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "SEED=42\n",
    "\n",
    "#Pipeline\n",
    "from joblib import dump, load\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "# import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1: ['pesim', 'peor', 'mal', 'suci', 'horribl', 'terribl', 'cobr', 'rob', 'habi', 'pag']\n",
      "Score 2: ['mal', 'decepcion', 'habit', 'asign', 'pobr', 'nadi', 'esper', 'dolar', 'ped', 'oli']\n",
      "Score 3: ['bastant', 'normal', 'embarg', 'aunqu', 'falt', 'monument', 'men', 'demasi', 'viv', 'general']\n",
      "Score 4: ['buen', 'limpi', 'excelent', 'comod', 'agrad', 'disfrut', 'ciud', 'ques', 'centr', 'hermos']\n",
      "Score 5: ['excelent', 'delici', 'recomend', 'increibl', 'encant', 'hermos', 'atencion', 'maravill', 'color', 'perfect']\n",
      "\n",
      "Evaluation Metrics:\n",
      "Train Accuracy: 0.7997070670084219\n",
      "Train Recall (Weighted): 0.7997070670084219\n",
      "Train F1-Score (Weighted): 0.7983510861142579\n",
      "Test Accuracy: 0.4884713919726729\n",
      "Test Recall (Weighted): 0.4884713919726729\n",
      "Test F1-Score (Weighted): 0.4791736134413112\n",
      "Confusion Matrix: [[ 78  86  38  15  20]\n",
      " [ 46 133 111  35  23]\n",
      " [ 11  57 162 152  84]\n",
      " [  4  24  81 254 226]\n",
      " [  1   4  31 149 517]]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import tokenize_text\n",
    "\n",
    "def create_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(tokenizer=tokenize_text)),\n",
    "        ('model', LogisticRegression(multi_class='multinomial', max_iter=1000))\n",
    "    ])\n",
    "    dump(pipeline, 'assets/pipeline.joblib')\n",
    "    return pipeline\n",
    "\n",
    "def train_evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test):\n",
    "    # Entrenar el pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    dump(pipeline, 'assets/pipeline.joblib')\n",
    "\n",
    "    # Predecir en los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de evaluación para el conjunto de entrenamiento\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "    # Calcular métricas de evaluación para el conjunto de prueba\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # Calcular la matriz de confusión para el conjunto de prueba\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    # Devolver las métricas de evaluación\n",
    "    return {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Train Recall (Weighted)': train_recall,\n",
    "        'Train F1-Score (Weighted)': train_f1,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Recall (Weighted)': test_recall,\n",
    "        'Test F1-Score (Weighted)': test_f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "def get_top_features(pipeline):\n",
    "    # Obtener el vectorizador TF-IDF del pipeline\n",
    "    tfidf_vectorizer = pipeline.named_steps['tfidf']\n",
    "    # Obtener los nombres de las características\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    # Obtener el modelo del pipeline\n",
    "    model = pipeline.named_steps['model']\n",
    "    coefficients = model.coef_\n",
    "\n",
    "    # Inicializar la lista de palabras más importantes por score\n",
    "    top_words_by_score = []\n",
    "\n",
    "    # Obtener las palabras más influyentes para cada score\n",
    "    for i, score_coefficients in enumerate(coefficients):\n",
    "        sorted_indices = np.argsort(score_coefficients)\n",
    "        top_indices = sorted_indices[-10:]  # Obtener los índices de las 10 palabras principales\n",
    "        top_indices = top_indices[::-1]  # Invertir para obtener las palabras con los coeficientes más altos primero\n",
    "        top_words = [feature_names[idx] for idx in top_indices]\n",
    "        top_words_by_score.append(top_words)\n",
    "\n",
    "    return top_words_by_score\n",
    "\n",
    "\n",
    "#Cargar datos\n",
    "df_original = pd.read_csv('../data/tipo1_entrenamiento_estudiantes.csv')\n",
    "df_prep = df_original.drop_duplicates()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_prep[\"Review\"], df_prep[\"Class\"], test_size=0.3, stratify=df_prep[\"Class\"], random_state=42)\n",
    "\n",
    "# Utilizar la función para evaluar el pipeline\n",
    "pipeline = create_pipeline()\n",
    "evaluation_metrics = train_evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test)\n",
    "top_features = get_top_features(pipeline)\n",
    "for i, score_words in enumerate(top_features, start=1):\n",
    "    print(f\"Score {i}: {score_words}\")\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for metric, value in evaluation_metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7774    La comida es increíble y el servicio es bueno....\n",
      "7250    Era interesante ver cómo vivían los Montejos m...\n",
      "65      Es un hotel muy grande, con muchos lugares par...\n",
      "3345    Fuimos a cenar hace unos días. La comida y el ...\n",
      "5413    Me encanto el lugar, la comida esta muy rica y...\n",
      "Name: Review, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andresarevalo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andresarevalo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "Prediction 1: La comida es increíble y el servicio es bueno. Si quieres conocer los sabores de la región es el mejor lugar y el precio es razonable. - Predicted Class: [0.14681601 0.16062587 0.16229536 0.14366555 0.38659721]\n",
      "Prediction 2: Era interesante ver cómo vivían los Montejos mientras estaban ocupados robar la tierra esclavizantes y su gente. - Predicted Class: [0.2001508  0.22415507 0.22713982 0.13877314 0.20978117]\n",
      "Prediction 3: Es un hotel muy grande, con muchos lugares para conocer, solo estuvimos dos noches, y en el dia aprovechamos a conocer la habana, de esta manera quiero aclarar que es un lindo hotel, pero si vas en pareja y tan pocos dias, como en nuestro caso no lo aprovechas! Aprovechen los buffets que hay en el mismo edificio, sobre todo en planta baja y en la esquina de la manzana, porque se come muy bien y barato! Aprovechen los restaurants del edificio, porque se come muy economico y mejor que afuera en la Habana. Nosotros estuvimos en un 5 piso, y daba al contrafrente, de no ser porque llovia, es una muy buena vista de la ciudad. - Predicted Class: [0.16965112 0.18732075 0.26142801 0.12232322 0.2592769 ]\n",
      "Prediction 4: Fuimos a cenar hace unos días. La comida y el ambiente era genial. El servicio es excelente, rápido y eficiente. Mi marido tenía el combo de camarones y costillas, absolutamente delicioso. Tuve la ensalada de taco de pollo, que era perfecta, el pollo marinado era tierna y bien preparado. Un valor fiable, planeamos volver mientras esté aquí en Nuevo Vallarta - Predicted Class: [0.14692956 0.16020599 0.16180519 0.24787545 0.28318381]\n",
      "Prediction 5: Me encanto el lugar, la comida esta muy rica y recién hecha se nota que el chef cuida cada detalle pera que todo sea perfecto, y puedes vivir una experiencia completa con bebida, comida y postre hindú.\n",
      "\n",
      "El servicio es de lo mejor, te guían...Más - Predicted Class: [0.13499474 0.14709981 0.14855521 0.13606181 0.43328843]\n"
     ]
    }
   ],
   "source": [
    "def predict_with_pipeline(pipeline,input_df):\n",
    "    # Realizar la predicción utilizando el pipeline\n",
    "    probabilities = pipeline.predict_proba(input_df)\n",
    "\n",
    "    # Devolver las probabilidades\n",
    "    return probabilities\n",
    "\n",
    "# Llamada a la función para obtener las predicciones\n",
    "input_df = pd.read_csv('../data/tipo1_entrenamiento_estudiantes.csv')\n",
    "# Seleccione 5 filas para predecir aleatoriamente\n",
    "input_df_sample = input_df.sample(5)['Review']\n",
    "print(input_df_sample)\n",
    "# Cargar el pipeline desde el archivo joblib\n",
    "pipeline = load('assets/pipeline.joblib')\n",
    "predictions = predict_with_pipeline(pipeline,input_df_sample)\n",
    "\n",
    "# Imprimir las predicciones\n",
    "print(\"\\nPredictions:\")\n",
    "for i, prediction in enumerate(predictions, start=1):\n",
    "    print(f\"Prediction {i}: {input_df_sample.iloc[i-1]} - Predicted Class: {prediction}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
