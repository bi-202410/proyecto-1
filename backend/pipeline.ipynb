{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "    roc_auc_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "SEED=42\n",
    "\n",
    "#Pipeline\n",
    "from joblib import dump, load\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "# import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1: ['pesim', 'peor', 'mal', 'suci', 'horribl', 'terribl', 'cobr', 'rob', 'habi', 'pag']\n",
      "Score 2: ['mal', 'decepcion', 'habit', 'asign', 'pobr', 'nadi', 'esper', 'dolar', 'ped', 'oli']\n",
      "Score 3: ['bastant', 'normal', 'embarg', 'aunqu', 'falt', 'monument', 'men', 'demasi', 'viv', 'general']\n",
      "Score 4: ['buen', 'limpi', 'excelent', 'comod', 'agrad', 'disfrut', 'ciud', 'ques', 'centr', 'hermos']\n",
      "Score 5: ['excelent', 'delici', 'recomend', 'increibl', 'encant', 'hermos', 'atencion', 'maravill', 'color', 'perfect']\n",
      "\n",
      "Evaluation Metrics:\n",
      "Train Accuracy: 0.7997070670084219\n",
      "Train Recall (Weighted): 0.7997070670084219\n",
      "Train F1-Score (Weighted): 0.7983510861142579\n",
      "Test Accuracy: 0.4884713919726729\n",
      "Test Recall (Weighted): 0.4884713919726729\n",
      "Test F1-Score (Weighted): 0.4791736134413112\n",
      "Confusion Matrix: [[ 78  86  38  15  20]\n",
      " [ 46 133 111  35  23]\n",
      " [ 11  57 162 152  84]\n",
      " [  4  24  81 254 226]\n",
      " [  1   4  31 149 517]]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import tokenize_text\n",
    "\n",
    "def create_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(tokenizer=tokenize_text)),\n",
    "        ('model', LogisticRegression(multi_class='multinomial', max_iter=1000))\n",
    "    ])\n",
    "    dump(pipeline, 'assets/pipeline.joblib')\n",
    "    return pipeline\n",
    "\n",
    "def train_evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test):\n",
    "    # Entrenar el pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    dump(pipeline, 'assets/pipeline.joblib')\n",
    "\n",
    "    # Predecir en los conjuntos de entrenamiento y prueba\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de evaluación para el conjunto de entrenamiento\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "    # Calcular métricas de evaluación para el conjunto de prueba\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # Calcular la matriz de confusión para el conjunto de prueba\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    # Devolver las métricas de evaluación\n",
    "    return {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Train Recall (Weighted)': train_recall,\n",
    "        'Train F1-Score (Weighted)': train_f1,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Test Recall (Weighted)': test_recall,\n",
    "        'Test F1-Score (Weighted)': test_f1,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "def get_top_features(pipeline):\n",
    "    # Obtener el vectorizador TF-IDF del pipeline\n",
    "    tfidf_vectorizer = pipeline.named_steps['tfidf']\n",
    "    # Obtener los nombres de las características\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    # Obtener el modelo del pipeline\n",
    "    model = pipeline.named_steps['model']\n",
    "    coefficients = model.coef_\n",
    "\n",
    "    # Inicializar la lista de palabras más importantes por score\n",
    "    top_words_by_score = []\n",
    "\n",
    "    # Obtener las palabras más influyentes para cada score\n",
    "    for i, score_coefficients in enumerate(coefficients):\n",
    "        sorted_indices = np.argsort(score_coefficients)\n",
    "        top_indices = sorted_indices[-10:]  # Obtener los índices de las 10 palabras principales\n",
    "        top_indices = top_indices[::-1]  # Invertir para obtener las palabras con los coeficientes más altos primero\n",
    "        top_words = [feature_names[idx] for idx in top_indices]\n",
    "        top_words_by_score.append(top_words)\n",
    "\n",
    "    return top_words_by_score\n",
    "\n",
    "\n",
    "#Cargar datos\n",
    "df_original = pd.read_csv('../data/tipo1_entrenamiento_estudiantes.csv')\n",
    "df_prep = df_original.drop_duplicates()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_prep[\"Review\"], df_prep[\"Class\"], test_size=0.3, stratify=df_prep[\"Class\"], random_state=42)\n",
    "\n",
    "# Utilizar la función para evaluar el pipeline\n",
    "pipeline = create_pipeline()\n",
    "evaluation_metrics = train_evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test)\n",
    "top_features = get_top_features(pipeline)\n",
    "for i, score_words in enumerate(top_features, start=1):\n",
    "    print(f\"Score {i}: {score_words}\")\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for metric, value in evaluation_metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600     Excelente lugar, muy atentos desde el Sr. Arma...\n",
      "7358    .Visitamos la Habana hace algunos días con mis...\n",
      "6827    El lugar es una maravilla que merece ser visit...\n",
      "6299    El mejoramiento continuo debe ser importante ,...\n",
      "7718    Excelente ubicación.. Buenos servicios alreded...\n",
      "Name: Review, dtype: object\n",
      "\n",
      "Predictions:\n",
      "Prediction 1: Excelente lugar, muy atentos desde el Sr. Armando que nos llevo en el trasporte todo un profesional y bien puesta la camiseta de la hacienda y de Merida, el guía profesional 100% y el lugar se ve de ensueño para quedarse un par de noches,  felicidades - Predicted Class: 5\n",
      "Prediction 2: .Visitamos la Habana hace algunos días con mis amigas y realmente  fue  muy desagradable pasar 2 días en este Hotel , está muy mal tenido , aire acondicionado en mal estado ,ducha mala , paredes con filtración de humedad... y que decir de los pasillos , la alfombra da susto... Al dar aviso a mantención reclamando el aire acondicionado , ya que era insufrible estar  con esa temperatura... nos trasladaron a las 2:00 AM .. después de estar más de 3 horas llamando permanentemente , El ingreso al Hotel no presagia lo encontrarás en la habitación .. REALMENTE UNA DESILUCIÓN!!! - Predicted Class: 1\n",
      "Prediction 3: El lugar es una maravilla que merece ser visitado. El servicio de cobro es pésimo y no es por el dinero porque mucha gente entra gratis, se hacen filas de más de 1 hora para pasar a pleno sol y mucha gente se mete disque al baño y no hace fila. Esta muy desorganizado. - Predicted Class: 5\n",
      "Prediction 4: El mejoramiento continuo debe ser importante , los alimentos y la bebidas deben de mejorar\n",
      "ademas de que es mejor tomar coca que pepsi\n",
      "variedad en la carne es necesario que se considere\n",
      "la showtime debe de ser mas variado y con personas que sepan - Predicted Class: 5\n",
      "Prediction 5: Excelente ubicación.. Buenos servicios alrededor.. Restaurante sumamente caro. Personal atento tanto en lobby como valet parking. Las habitaciones confortables y con muchos USB chargers para los gases. - Predicted Class: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.4.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict_with_pipeline(pipeline,input_df):\n",
    "    # Realizar la predicción utilizando el pipeline\n",
    "    predictions = pipeline.predict(input_df)\n",
    "\n",
    "    # Devolver las predicciones\n",
    "    return predictions\n",
    "\n",
    "# Llamada a la función para obtener las predicciones\n",
    "input_df = pd.read_csv('../data/tipo1_entrenamiento_estudiantes.csv')\n",
    "# Seleccione 5 filas para predecir aleatoriamente\n",
    "input_df_sample = input_df.sample(5)['Review']\n",
    "print(input_df_sample)\n",
    "# Cargar el pipeline desde el archivo joblib\n",
    "pipeline = load('assets/pipeline.joblib')\n",
    "predictions = predict_with_pipeline(pipeline,input_df_sample)\n",
    "\n",
    "# Imprimir las predicciones\n",
    "print(\"\\nPredictions:\")\n",
    "for i, prediction in enumerate(predictions, start=1):\n",
    "    print(f\"Prediction {i}: {input_df_sample.iloc[i-1]} - Predicted Class: {prediction}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
